import os
import pickle
import logging

import numpy as np
import faiss
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
load_dotenv()
RAG_BOT_TOKEN = os.getenv("RAG_BOT_TOKEN")

MODEL_NAME = 'all-MiniLM-L6-v2'
STORE_PATH = 'vector_store'
INDEX_FILE = os.path.join(STORE_PATH, 'index.faiss')
MAP_FILE = os.path.join(STORE_PATH, 'message_map.pkl')

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
TOP_K = 3

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ---
# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ –±–∞–∑—É –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –±–æ—Ç–∞ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
model = None
faiss_index = None
message_map = None

# --- –§—É–Ω–∫—Ü–∏–∏-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–∏ –∫–æ–º–∞–Ω–¥–µ /start."""
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–∂–µ—Ç —Ç–µ–±–µ –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∞—Ä—Ö–∏–≤–µ —á–∞—Ç–∞.\n"
        "–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å, –∏ —è –Ω–∞–π–¥—É –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è."
    )

async def search(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ."""
    user_query = update.message.text
    
    if not faiss_index or not message_map:
        await update.message.reply_text("–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –µ—â–µ –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        return

    logger.info(f"–ü–æ–ª—É—á–µ–Ω –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: '{user_query}'")

    # 1. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –≤–µ–∫—Ç–æ—Ä
    query_vector = model.encode([user_query])
    
    # 2. –ò—â–µ–º –≤ FAISS K –±–ª–∏–∂–∞–π—à–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤
    # search –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è (D) –∏ –∏–Ω–¥–µ–∫—Å—ã (I)
    distances, indices = faiss_index.search(np.array(query_vector).astype('float32'), TOP_K)

    # 3. –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
    results = []
    found_indices = indices[0] # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ (–∏ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ) –∑–∞–ø—Ä–æ—Å–∞
    
    # –£–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å -1, –µ—Å–ª–∏ –∏—Ö –º–µ–Ω—å—à–µ —á–µ–º TOP_K
    valid_indices = [i for i in found_indices if i != -1]
    
    if not valid_indices:
        await update.message.reply_text("–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–∏—á–µ–≥–æ –ø–æ—Ö–æ–∂–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return

    for i in valid_indices:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –Ω–∞—à–µ–π –∫–∞—Ä—Ç—ã
        message_data = message_map.get(i)
        if message_data:
            results.append(message_data['text'])

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤ –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
    response_text = "–í–æ—Ç —á—Ç–æ —è –Ω–∞—à–µ–ª:\n\n"
    response_text += "\n\n---\n\n".join(f"üîπ {text}" for text in results)

    await update.message.reply_text(response_text)


def main() -> None:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞."""
    global model, faiss_index, message_map

    if not RAG_BOT_TOKEN:
        logger.error("–¢–æ–∫–µ–Ω RAG-–±–æ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ .env —Ñ–∞–π–ª.")
        return

    # --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ ---
    try:
        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ ML-–º–æ–¥–µ–ª–∏...")
        model = SentenceTransformer(MODEL_NAME)
        logger.info("ML-–º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞...")
        faiss_index = faiss.read_index(INDEX_FILE)
        with open(MAP_FILE, 'rb') as f:
            message_map = pickle.load(f)
        logger.info(f"–•—Ä–∞–Ω–∏–ª–∏—â–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ. –í –∏–Ω–¥–µ–∫—Å–µ {faiss_index.ntotal} –≤–µ–∫—Ç–æ—Ä–æ–≤.")

    except FileNotFoundError:
        logger.warning(
            "–§–∞–π–ª—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. "
            "–ë–æ—Ç –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å, –Ω–æ –ø–æ–∏—Å–∫ –Ω–µ –¥–∞—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –ø–æ–∫–∞ —Å–∫–∞–Ω–µ—Ä –Ω–µ —Å–æ–∑–¥–∞—Å—Ç –±–∞–∑—É."
        )
    except Exception as e:
        logger.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return

    # --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –∑–∞–ø—É—Å–∫ —Å–∞–º–æ–≥–æ –±–æ—Ç–∞ ---
    application = Application.builder().token(RAG_BOT_TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    # –û—Ç–≤–µ—á–∞–µ–º –Ω–∞ –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –∫–æ–º–∞–Ω–¥–∞–º–∏
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, search))

    logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
    application.run_polling()


if __name__ == "__main__":
    main()